{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3a2f93",
   "metadata": {},
   "source": [
    "# **Gathering all the metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce71635",
   "metadata": {},
   "source": [
    "This notebook analyzes and compares the performance of various machine learning models on mushrooms dataset. The goal is to determine which model performs best based on standard evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88d759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0aea4",
   "metadata": {},
   "source": [
    "## **Step 1: Collect Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aef16f",
   "metadata": {},
   "source": [
    "We gather manually the evaluation metrics from each model, including accuracy, precision, recall, F1-score, and confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef169679",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    {\n",
    "        \"Model\": \"Logistic Regression\",\n",
    "        \"Accuracy\": 0.99995,\n",
    "        \"Precision_e\": 1.00,\n",
    "        \"Precision_p\": 1.00,\n",
    "        \"Recall_e\": 1.00,\n",
    "        \"Recall_p\": 1.00,\n",
    "        \"F1_e\": 1.00,\n",
    "        \"F1_p\": 1.00,\n",
    "        \"Confusion_Matrix\": [[1052, 0], [2, 977]]\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Decision Tree\",\n",
    "        \"Accuracy\": 1.0000,\n",
    "        \"Precision_e\": 1.00,\n",
    "        \"Precision_p\": 1.00,\n",
    "        \"Recall_e\": 1.00,\n",
    "        \"Recall_p\": 1.00,\n",
    "        \"F1_e\": 1.00,\n",
    "        \"F1_p\": 1.00,\n",
    "        \"Confusion_Matrix\": [[843, 0], [0, 782]]\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"KNN\",\n",
    "        \"Accuracy\": 1.0000,\n",
    "        \"Precision_e\": 1.00,\n",
    "        \"Precision_p\": 1.00,\n",
    "        \"Recall_e\": 1.00,\n",
    "        \"Recall_p\": 1.00,\n",
    "        \"F1_e\": 1.00,\n",
    "        \"F1_p\": 1.00,\n",
    "        \"Confusion_Matrix\": [[843, 0], [0, 782]]\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"SVM\",\n",
    "        \"Accuracy\": 1.0000,\n",
    "        \"Precision_e\": 1.00,\n",
    "        \"Precision_p\": 1.00,\n",
    "        \"Recall_e\": 1.00,\n",
    "        \"Recall_p\": 1.00,\n",
    "        \"F1_e\": 1.00,\n",
    "        \"F1_p\": 1.00,\n",
    "        \"Confusion_Matrix\": [[843, 0], [0, 782]]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc198ca",
   "metadata": {},
   "source": [
    "## **Step 2: Organize Data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015c16d",
   "metadata": {},
   "source": [
    "Compile the collected metrics into a structured DataFrame for easier comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7d0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a6c4c",
   "metadata": {},
   "source": [
    "## **Step 3: Analyze and Compare**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d2d96",
   "metadata": {},
   "source": [
    "Display a summary table of key metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95886d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary Table:\")\n",
    "print(df_metrics.drop(columns=[\"Confusion_Matrix\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af7c65",
   "metadata": {},
   "source": [
    "All models achieved perfect or near-perfect performance on the test set — a strong indicator that the dataset may be linearly separable and well-suited to classification.\n",
    "- Logistic Regression had a minor misclassification (2 errors), but cross-validation showed very consistent results (mean CV accuracy ≈ 0.9995).\n",
    "\n",
    "- KNN, SVM, and Decision Tree showed flawless performance on the test set, with no misclassifications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5dfb49",
   "metadata": {},
   "source": [
    "## **Step 4: Visualize**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe380c",
   "metadata": {},
   "source": [
    "We use bar plots and heatmaps to visually compare the performance of each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21106b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_metrics, x=\"Model\", y=\"Accuracy\")\n",
    "plt.ylim(0.99, 1.01)\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e753f",
   "metadata": {},
   "source": [
    "Visual comparison of how each model classified the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0be4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_data in metrics:\n",
    "    plt.figure()\n",
    "    sns.heatmap(model_data[\"Confusion_Matrix\"], annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {model_data['Model']}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482c403",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc835b8",
   "metadata": {},
   "source": [
    "All evaluated models — Logistic Regression, Decision Tree, K-Nearest Neighbors (KNN), and Support Vector Machine (SVM) — achieved near-identical results, with perfect or near-perfect scores across all performance metrics including accuracy, precision, recall, and F1 scores. \n",
    "\n",
    "Given this parity in performance, we opted for Logistic Regression as the final model due to its simplicity, low computational cost, and ease of interpretation. \n",
    "\n",
    "Logistic Regression is well-suited for problems where the data is linearly separable or when complex decision boundaries are unnecessary. Choosing the simplest effective model helps reduce the risk of overfitting, facilitates faster training and prediction, and improves overall model transparency — all desirable qualities for a robust and efficient solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
