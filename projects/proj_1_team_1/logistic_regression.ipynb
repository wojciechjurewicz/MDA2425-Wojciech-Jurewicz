{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc29210",
   "metadata": {},
   "source": [
    "## **Logistic Regresion Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c450df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd4401",
   "metadata": {},
   "source": [
    "Before training the model, we'll split the data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b640b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe35394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "while any(marker in os.getcwd() for marker in ('exercises', 'notebooks', 'students', 'research', 'projects')):\n",
    "    os.chdir(\"..\")\n",
    "os.chdir(\"projects/proj_1_team_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a9616",
   "metadata": {},
   "source": [
    "# **Load of the preprocessed dataframe from .csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c48d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mushrooms_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b640b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d463daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='poisonous')\n",
    "y = df['poisonous']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = make_pipeline(LogisticRegression(max_iter=1000))\n",
    "logreg_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1a73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline.fit(X_train, y_train)\n",
    "y_pred = logreg_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb166db6",
   "metadata": {},
   "source": [
    "Let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ab7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(logreg_pipeline, X_train, y_train, cv=10)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean cross-validation accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Edible','Poisonous'], yticklabels=['Edible','Poisonous'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9caeaa",
   "metadata": {},
   "source": [
    "# **Learning curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea5ffe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve( logreg_pipeline, X_train, y_train, cv=10, train_sizes=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3d3c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_scores.mean(axis=1)\n",
    "valid_mean = valid_scores.mean(axis=1)\n",
    "\n",
    "train_std = train_scores.std(axis=1)\n",
    "valid_std = valid_scores.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29401c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_percent = (train_sizes / len(X_train)) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes_percent, train_mean, label='Training Accuracy', color='blue')\n",
    "plt.plot(train_sizes_percent, valid_mean, label='Validation Accuracy', color='green')\n",
    "\n",
    "plt.fill_between(train_sizes_percent, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
    "plt.fill_between(train_sizes_percent, valid_mean - valid_std, valid_mean + valid_std, color='green', alpha=0.2)\n",
    "\n",
    "plt.title('Learning Curve for Logistic Regression')\n",
    "plt.xlabel('Training Size (%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
