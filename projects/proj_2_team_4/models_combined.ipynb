{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "while any(marker in os.getcwd() for marker in ('exercises', 'notebooks', 'students', 'research', 'projects')):\n",
    "    os.chdir(\"..\")\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import plotly.graph_objects as go\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# Machine Learning & Modeling\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    root_mean_squared_log_error,  # Metric used in the competition\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow tracking URI to local directory\n",
    "mlflow.set_tracking_uri(\"projects/proj_2_team_4/mlruns\")\n",
    "\n",
    "# Use for running ui:\n",
    "# mlflow ui --backend-store-uri \"Absolute path\"\n",
    "# e.g.: mlflow ui --backend-store-uri \"/Users/wojciechjurewicz/Desktop/Multivariate Data Analysis/Lab/mda2425/projects/proj_2_team_4/mlruns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the correct .env file location\n",
    "env_path = 'projects/proj_2_team_4/.env'\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_catboost_path = os.getenv('TRAIN_RAW_MERGED_PATH')\n",
    "train_preprocessed_path = os.getenv('TRAIN_PREPROCESSED_PATH')\n",
    "train_preprocessed_log_path = os.getenv('TRAIN_PREPROCESSED_LOG_PATH')\n",
    "\n",
    "test_catboost_path = os.getenv('VALID_RAW_MERGED_PATH')\n",
    "test_preprocessed_path = os.getenv('VALID_PREPROCESSED_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_catboost = pd.read_csv(train_catboost_path)\n",
    "df_train_preprocessed = pd.read_csv(train_preprocessed_path)\n",
    "df_train_log_preprocessed = pd.read_csv(train_preprocessed_log_path)\n",
    "\n",
    "df_test = pd.read_csv(test_preprocessed_path)\n",
    "df_test_catboost = pd.read_csv(test_catboost_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid sets split in different ways, we will use the same indices for all sets\n",
    "# Different set sizes cause issues when reversing log-transfor on SalePrice\n",
    "\n",
    "# Step 1: Generate consistent indices for the split\n",
    "train_idx, valid_idx = train_test_split(df_train_preprocessed.index, test_size=0.10, random_state=42)\n",
    "\n",
    "# Step 2: Use these indices to slice all your DataFrames\n",
    "train_df_catboost = df_train_catboost.loc[train_idx]\n",
    "valid_df_catboost = df_train_catboost.loc[valid_idx]\n",
    "\n",
    "train_df = df_train_preprocessed.loc[train_idx]\n",
    "valid_df = df_train_preprocessed.loc[valid_idx]\n",
    "\n",
    "train_df_log = df_train_log_preprocessed.loc[train_idx]\n",
    "valid_df_log = df_train_log_preprocessed.loc[valid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_catboost = train_df_catboost.drop(columns=[\"SalePrice\"])\n",
    "y_train_catboost = train_df_catboost[\"SalePrice\"]\n",
    "\n",
    "X_train = train_df.drop(columns=[\"SalePrice\"])\n",
    "y_train = train_df[\"SalePrice\"]\n",
    "\n",
    "X_train_log = train_df_log.drop(columns=[\"SalePrice\"])\n",
    "y_train_log = train_df_log[\"SalePrice\"]\n",
    "\n",
    "\n",
    "\n",
    "X_valid_catboost = valid_df_catboost.drop(columns=[\"SalePrice\"])\n",
    "y_valid_catboost = valid_df_catboost[\"SalePrice\"]\n",
    "\n",
    "X_valid = valid_df.drop(columns=[\"SalePrice\"])\n",
    "y_valid = valid_df[\"SalePrice\"]\n",
    "\n",
    "X_valid_log = valid_df_log.drop(columns=[\"SalePrice\"])\n",
    "y_valid_log = valid_df_log[\"SalePrice\"]\n",
    "\n",
    "\n",
    "X_test_catboost = df_test_catboost.drop(columns=[\"SalePrice\"])\n",
    "X_test = df_test.drop(columns=[\"SalePrice\"])\n",
    "\n",
    "valid_solutions_path = os.getenv(\"VALID_SOLUTIONS_PATH\")\n",
    "df_valid_solutions = pd.read_csv(valid_solutions_path)\n",
    "#df_valid_solutions = pd.read_csv(\"projects/proj_2_team_4/datasets/ValidSolution.csv\")\n",
    "y_test = df_test[\"SalePrice\"]\n",
    "\n",
    "y_test_catboost = df_test_catboost[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main base class for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModelTuner:\n",
    "    def __init__(self, model_name, X_train, y_train, X_valid, y_valid, inverse_transform=None, run_name=None):\n",
    "        self.model_name = model_name\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.inverse_transform = inverse_transform or (lambda x: x)  # Default: identity function\n",
    "        self.run_name = run_name\n",
    "\n",
    "    def define_search_space(self, trial):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build_model(self, params):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def objective(self, trial=None, params=None):\n",
    "        start = time.time()\n",
    "\n",
    "        # 1) Sample hyperparameters & build the model\n",
    "        if trial is not None:\n",
    "            params = self.define_search_space(trial)\n",
    "        model = self.build_model(params)\n",
    "\n",
    "        # 2) Fit and get raw predictions\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred_raw = model.predict(self.X_valid)\n",
    "\n",
    "        # 3) Clip to [0, ∞), then invert the transformation\n",
    "\n",
    "        y_pred = np.maximum(0, y_pred_raw)\n",
    "        y_pred = self.inverse_transform(y_pred)\n",
    "        \n",
    "        # 4) Bail early if any preds are infinite or NaN\n",
    "        if not np.all(np.isfinite(y_pred)):\n",
    "            # Return an infinite loss so Optuna discards this trial\n",
    "            return float(\"inf\"), time.time() - start\n",
    "\n",
    "        # 5) Compute metrics against the *raw* y_valid\n",
    "        rmsle_val = root_mean_squared_log_error(self.y_valid, y_pred)\n",
    "        r2_val    = r2_score(self.y_valid, y_pred)\n",
    "        training_time = time.time() - start\n",
    "\n",
    "        # 6) Log to MLflow\n",
    "        mlflow.set_experiment(self.model_name)\n",
    "        with mlflow.start_run(run_name=self.run_name, nested=True):\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics({\n",
    "                \"RMSLE\": rmsle_val,\n",
    "                \"R2\": r2_val,\n",
    "                \"training_time\": training_time\n",
    "            })\n",
    "            if trial is None:\n",
    "                mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # 7) Return for multi‐objective (RMSLE, time)\n",
    "        return rmsle_val, training_time\n",
    "\n",
    "\n",
    "    def run_study(self, n_trials=30, timeout=None, show_progress_bar=True):\n",
    "        self.study = optuna.create_study(\n",
    "            directions=[\"minimize\", \"minimize\"],\n",
    "            study_name=self.model_name\n",
    "        )\n",
    "        self.study.optimize(self.objective, n_trials=n_trials, timeout=timeout, show_progress_bar=show_progress_bar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return LinearRegression(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegressionTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-4, 100.0),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"saga\"]),\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return Ridge(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegressionTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-4, 100.0)\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return Lasso(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 5, 15),\n",
    "        \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "        \"algorithm\": trial.suggest_categorical(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]),\n",
    "        \"leaf_size\": trial.suggest_int(\"leaf_size\", 20, 40),\n",
    "        \"p\": trial.suggest_int(\"p\", 1, 2),  # 1 = Manhattan, 2 = Euclidean\n",
    "        \"metric\": \"minkowski\",\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return KNeighborsRegressor(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosterRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 13),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),    \n",
    "            \"n_iter_no_change\":   10,\n",
    "            \"validation_fraction\": 0.1,\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 15),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 8),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return RandomForestRegressor(**params, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron Regressor (MLPRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"hidden_layer_sizes\": trial.suggest_categorical(\"hidden_layer_sizes\", [(50,), (100,), (100,50)]),\n",
    "            \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-5, 1e-1),\n",
    "            \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"constant\", \"adaptive\"]),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 200, 1000),\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return MLPRegressor(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"tree_method\": trial.suggest_categorical(\"tree_method\", [\"approx\", \"hist\"])\n",
    "    }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 12),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 8),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"]),\n",
    "        }\n",
    "\n",
    "    def build_model(self, params):\n",
    "        return DecisionTreeRegressor(**params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostTuner(BaseModelTuner):\n",
    "    def define_search_space(self, trial):\n",
    "        return {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0),\n",
    "        }\n",
    " \n",
    "    def build_model(self, params):\n",
    "        return CatBoostRegressor(**params, loss_function=\"RMSE\", verbose=False)\n",
    " \n",
    "    def objective(self, trial=None, params=None):\n",
    "        y_train_mod = np.log1p(self.y_train) # CatBoost does not have RMSLE loss function. We use RMSE and proper transformation instead.\n",
    " \n",
    "        cat_feats = self.X_train.select_dtypes(['object','category']).columns.tolist()\n",
    " \n",
    "        for c in cat_feats:\n",
    "            self.X_train[c] = self.X_train[c].astype(str)\n",
    "            self.X_valid[c] = self.X_valid[c].astype(str)\n",
    " \n",
    "        train_pool = Pool(self.X_train, y_train_mod, cat_features=cat_feats)\n",
    "        valid_pool = Pool(self.X_valid, cat_features=cat_feats)\n",
    " \n",
    "        start = time.time()\n",
    "        \n",
    "        if trial is not None:\n",
    "            params = self.define_search_space(trial)\n",
    "        model = self.build_model(params)\n",
    "\n",
    "        model.fit(train_pool)\n",
    "        preds_log = model.predict(valid_pool)\n",
    "        duration = time.time() - start\n",
    " \n",
    "        preds = np.expm1(preds_log)\n",
    "        score = root_mean_squared_log_error(self.y_valid, preds)\n",
    " \n",
    "        mlflow.set_experiment(self.model_name)\n",
    "        with mlflow.start_run(run_name=self.run_name, nested=True):\n",
    "            mlflow.log_params(model.get_params())\n",
    "            mlflow.log_metrics({\n",
    "                \"Validation RMSLE\": score,\n",
    "                \"training_time\": duration\n",
    "            })\n",
    "\n",
    "            if trial is None:\n",
    "                mlflow.sklearn.log_model(model, \"model\")\n",
    "                \n",
    "        return score, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config for studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_tag = datetime.now().strftime(\"%d.%m-%H:%M\")\n",
    "\n",
    "model_configs = [\n",
    "    {\n",
    "        \"model_cls\": KNTuner,\n",
    "        \"experiment_name\": f\"KNeighbours_{experiment_tag}\",\n",
    "        \"X_train\": X_train_log,\n",
    "        \"y_train\": y_train_log,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": np.expm1,\n",
    "        \"n_trials\": 30,\n",
    "        \"timeout\": 800,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": LinearRegressionTuner,\n",
    "        \"experiment_name\": f\"LinearRegression_{experiment_tag}\",\n",
    "        \"X_train\": X_train_log,\n",
    "        \"y_train\": y_train_log,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": np.expm1,\n",
    "        \"n_trials\": 2,\n",
    "        \"timeout\": 400,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": RidgeRegressionTuner,\n",
    "        \"experiment_name\": f\"RidgeRegression_{experiment_tag}\",\n",
    "        \"X_train\": X_train_log,\n",
    "        \"y_train\": y_train_log,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": np.expm1,\n",
    "        \"n_trials\": 20,\n",
    "        \"timeout\": 450,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": LassoRegressionTuner,\n",
    "        \"experiment_name\": f\"LassoRegression_{experiment_tag}\",\n",
    "        \"X_train\": X_train_log,\n",
    "        \"y_train\": y_train_log,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": np.expm1,\n",
    "        \"n_trials\": 10,\n",
    "        \"timeout\": 450,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": DecisionTreeTuner,\n",
    "        \"experiment_name\": f\"DecisionTree_{experiment_tag}\",\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": None,\n",
    "        \"n_trials\": 150,\n",
    "        \"timeout\": 800,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": GradientBoostingTuner,\n",
    "        \"experiment_name\": f\"GradientBoosting_{experiment_tag}\",\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": None,\n",
    "        \"n_trials\": 100,\n",
    "        \"timeout\": 800,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": RandomForestTuner,\n",
    "        \"experiment_name\": f\"RandomForest_{experiment_tag}\",\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": None,\n",
    "        \"n_trials\": 100,\n",
    "        \"timeout\": 800,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": MLPTuner,\n",
    "        \"experiment_name\": f\"MLP_{experiment_tag}\",\n",
    "        \"X_train\": X_train_log,\n",
    "        \"y_train\": y_train_log,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": np.expm1,\n",
    "        \"n_trials\": 100,\n",
    "        \"timeout\": 800,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": XGBoostTuner,\n",
    "        \"experiment_name\": f\"XGBoost_{experiment_tag}\",\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"inverse_transform\": None,\n",
    "        \"n_trials\": 200,\n",
    "        \"timeout\": 1100,\n",
    "    },\n",
    "    {\n",
    "        \"model_cls\": CatBoostTuner,\n",
    "        \"experiment_name\": f\"CatBoost_{experiment_tag}\",\n",
    "        \"X_train\": X_train_catboost,\n",
    "        \"y_train\": y_train_catboost,\n",
    "        \"X_valid\": X_valid_catboost,\n",
    "        \"y_valid\": y_valid_catboost,\n",
    "        \"X_test\":  X_test_catboost,\n",
    "        \"y_test\":  y_test_catboost,\n",
    "        \"inverse_transform\": None,\n",
    "        \"n_trials\": 200,\n",
    "        \"timeout\": 1100\n",
    "    },\n",
    "]\n",
    "\n",
    "# Shared params1\n",
    "for cfg in model_configs:\n",
    "    cfg.update({\n",
    "        \"show_progress_bar\": False,\n",
    "        \"run_name\": None\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_excluded = {\n",
    "   KNTuner,\n",
    "   LinearRegressionTuner,\n",
    "   RidgeRegressionTuner,\n",
    "   LassoRegressionTuner,\n",
    "   DecisionTreeTuner,\n",
    "   GradientBoostingTuner,\n",
    "   RandomForestTuner,\n",
    "   MLPTuner,\n",
    "   XGBoostTuner,\n",
    "   CatBoostTuner \n",
    "}\n",
    "\n",
    "model_configs = [\n",
    "   cfg\n",
    "   for cfg in model_configs\n",
    "   if cfg[\"model_cls\"] in not_excluded\n",
    "]\n",
    "\n",
    "# Set Optuna logging level to WARNING to suppress trial info\n",
    "optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
    "\n",
    "studies = {}\n",
    "\n",
    "def run_study(config):\n",
    "    try:\n",
    "        tuner = config[\"model_cls\"](\n",
    "            \"parallel_validation_set_\" + config[\"experiment_name\"],\n",
    "            config[\"X_train\"],\n",
    "            config[\"y_train\"],\n",
    "            config[\"X_valid\"],\n",
    "            config[\"y_valid\"],\n",
    "            inverse_transform=config.get(\"inverse_transform\")\n",
    "        )\n",
    "\n",
    "        print(f\"Running study for validation_set {config['model_cls'].__name__}. Time is {datetime.now().strftime('%d.%m-%H:%M')}\")\n",
    "\n",
    "        tuner.run_study(\n",
    "            n_trials=config[\"n_trials\"],\n",
    "            timeout=config[\"timeout\"],\n",
    "            show_progress_bar=config[\"show_progress_bar\"]\n",
    "        )\n",
    "        \n",
    "        fig = vis.plot_pareto_front(tuner.study, target_names=[\"RMSLE\", \"Training Time\"])\n",
    "        fig.update_layout(title=f\"{tuner.model_name} Pareto Front: RMSLE vs Training Time\")\n",
    "        fig.show()\n",
    "        \n",
    "        # Save the figure\n",
    "        fig.write_html(f\"{tuner.model_name}_pareto_front.html\")\n",
    "        fig.write_image(f\"{tuner.model_name}_pareto_front.png\")\n",
    "        \n",
    "        return tuner.model_name, tuner.study\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {config['model_cls'].__name__}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# Run studies in parallel using joblib\n",
    "results = Parallel(n_jobs=-1)(delayed(run_study)(config) for config in model_configs)\n",
    "    \n",
    "# Update studies dict with results\n",
    "studies.update(dict(filter(None, results)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing best models in RMSLE, training time, and combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(lst):\n",
    "    min_val, max_val = min(lst), max(lst)\n",
    "    if max_val == min_val:\n",
    "        return [0.0 for _ in lst]\n",
    "    return [(x - min_val) / (max_val - min_val) for x in lst]\n",
    "\n",
    "# Store all models and their metrics for final pareto plot\n",
    "all_models = []\n",
    "all_metrics = []\n",
    "all_params = []  # Added to store parameters\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = \"validation_set_\" + config[\"experiment_name\"]\n",
    "    study = studies.get(model_name)\n",
    "    if study is None:\n",
    "        print(f\"No study found for {model_name}\")\n",
    "        continue\n",
    "\n",
    "    trials = [t for t in study.trials if t.values is not None]\n",
    "    if not trials:\n",
    "        print(f\"No valid trials for {model_name}\")\n",
    "        continue\n",
    "\n",
    "    rmsle_vals = np.array([t.values[0] for t in trials])\n",
    "    time_vals = np.array([t.values[1] for t in trials])\n",
    "    rmsle_norm = normalize(rmsle_vals)\n",
    "    time_norm = normalize(time_vals)\n",
    "    combined = np.array([0.5 * r + 0.5 * t for r, t in zip(rmsle_norm, time_norm)])\n",
    "\n",
    "    n_select = max(2, int(np.ceil(0.01 * len(trials))))\n",
    "\n",
    "    idx_rmsle = np.argsort(rmsle_vals)\n",
    "    idx_time = np.argsort(time_vals)\n",
    "    idx_combined = np.argsort(combined)\n",
    "\n",
    "    selected = set()\n",
    "    def pick_unique(indices):\n",
    "        chosen = []\n",
    "        for idx in indices:\n",
    "            if idx not in selected:\n",
    "                chosen.append(idx)\n",
    "                selected.add(idx)\n",
    "            if len(chosen) == n_select:\n",
    "                break\n",
    "        return chosen\n",
    "\n",
    "    best_rmsle = pick_unique(idx_rmsle)\n",
    "    best_time = pick_unique(idx_time)\n",
    "    best_combined = pick_unique(idx_combined)\n",
    "    \n",
    "    # For each selected trial, retrain and log to MLflow\n",
    "    for category, indices in zip(\n",
    "        [\"best_rmsle\", \"best_time\", \"best_combined\"],\n",
    "        [best_rmsle, best_time, best_combined]\n",
    "    ):\n",
    "        for idx in indices:\n",
    "            trial = trials[idx]\n",
    "            params = trial.params\n",
    "\n",
    "            # Instantiate the correct tuner\n",
    "            try:\n",
    "                tuner = config[\"model_cls\"](\n",
    "                    \"test_set_results\"+\"_\"+experiment_tag,\n",
    "                    config[\"X_train\"],\n",
    "                    config[\"y_train\"],\n",
    "                    config[\"X_test\"],\n",
    "                    config[\"y_test\"],\n",
    "                    inverse_transform=config.get(\"inverse_transform\"),\n",
    "                    run_name=f\"{config['experiment_name']}_{category}_{idx}\"\n",
    "                )\n",
    "\n",
    "                print(f\"Running study for test_set {category, config['model_cls'].__name__}. Time is {datetime.now().strftime('%d.%m-%H:%M')}\")\n",
    "\n",
    "                # Train model and get metrics\n",
    "                rmsle, train_time = tuner.objective(trial=None, params=params)\n",
    "                \n",
    "                # Save model and metrics for pareto plot\n",
    "                all_models.append(f\"{config['experiment_name']}_{category}_{idx}\")\n",
    "                all_metrics.append((rmsle, train_time))\n",
    "                all_params.append(params)  # Store the parameters\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {config['model_cls'].__name__}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "# Create and save final pareto front plot\n",
    "if all_metrics:\n",
    "    rmsle_vals, time_vals = zip(*all_metrics)\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create hover text with parameters\n",
    "    hover_texts = []\n",
    "    for model_name, params in zip(all_models, all_params):\n",
    "        param_text = \"<br>\".join([f\"{k}: {v}\" for k, v in params.items()])\n",
    "        hover_texts.append(f\"{model_name}<br>Parameters:<br>{param_text}\")\n",
    "    \n",
    "    fig.add_scatter(\n",
    "        x=rmsle_vals,\n",
    "        y=time_vals,\n",
    "        mode='markers+text',\n",
    "        text=all_models,\n",
    "        textposition=\"top center\",\n",
    "        hovertext=hover_texts,\n",
    "        hoverinfo='text',\n",
    "        marker=dict(size=10)\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Pareto Front: All Models RMSLE vs Training Time\",\n",
    "        xaxis_title=\"RMSLE\",\n",
    "        yaxis_title=\"Training Time (s)\"\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    fig.write_html(\"pareto_front_all_models.html\")\n",
    "    mlflow.log_artifact(\"pareto_front_all_models.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
